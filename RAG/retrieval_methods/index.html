
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A technical reference Retrieval Augmented Generation And Context Engineering.">
      
      
        <meta name="author" content="Saurabh Goyal">
      
      
      
        <link rel="prev" href="../embedding/">
      
      
        <link rel="next" href="../indexing_and_vector_database/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Retrieval Methods - RAG & Context Engineering</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-overview" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="RAG &amp; Context Engineering" class="md-header__button md-logo" aria-label="RAG & Context Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            RAG & Context Engineering
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Retrieval Methods
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="deep-purple"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="lime"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/saurabhiit2007/RAG_And_Context_Engineering" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="RAG &amp; Context Engineering" class="md-nav__button md-logo" aria-label="RAG & Context Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    RAG & Context Engineering
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/saurabhiit2007/RAG_And_Context_Engineering" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Retrival Augmented Generation (RAG)
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Retrival Augmented Generation (RAG)
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chunking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chunking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Embedding
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Retrieval Methods
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Retrieval Methods
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. TF-IDF
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. TF-IDF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#term-frequency-tf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Term Frequency (TF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-document-frequency-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inverse Document Frequency (IDF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf-score" class="md-nav__link">
    <span class="md-ellipsis">
      
        TF-IDF Score
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-bm25-best-matching-25" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. BM25 (Best Matching 25)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. BM25 (Best Matching 25)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bm25-formula" class="md-nav__link">
    <span class="md-ellipsis">
      
        BM25 Formula
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-improvements-over-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Improvements Over TF-IDF
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bm25-vs-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        BM25 vs. TF-IDF
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-why-bm25-ranks-better" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example: Why BM25 Ranks Better
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-bm25" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use BM25
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-splade" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. SPLADE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. SPLADE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-splade-works-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        How SPLADE Works (Step by Step)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splade-scoring-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        SPLADE Scoring Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splade-vs-bm25" class="md-nav__link">
    <span class="md-ellipsis">
      
        SPLADE vs. BM25
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-splade" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use SPLADE
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-sentence-transformers-dense-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Sentence Transformers (Dense Retrieval)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Sentence Transformers (Dense Retrieval)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-they-work-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        How They Work (Step by Step)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-mean-pooling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Mean Pooling?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sentence-transformers-vs-sparse-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sentence Transformers vs. Sparse Retrieval
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-retrieval-method-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Retrieval Method Comparison
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-interview-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Interview Questions
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../indexing_and_vector_database/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Indexing Strategies, Vector Databases, and Retrieval Systems for RAG
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Re-Ranking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../advanced_rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Advanced RAG
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quick_reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quick Reference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_10" >
        
          
          <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Supporting Concepts
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Supporting Concepts
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supporting_topics/tf_idf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    TF_IDF
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supporting_topics/bm25/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BM25
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supporting_topics/splade/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Splade
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../supporting_topics/sentence_transformers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sentence Transformer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../references/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    References
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. TF-IDF
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. TF-IDF">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#term-frequency-tf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Term Frequency (TF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inverse-document-frequency-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inverse Document Frequency (IDF)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tf-idf-score" class="md-nav__link">
    <span class="md-ellipsis">
      
        TF-IDF Score
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-bm25-best-matching-25" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. BM25 (Best Matching 25)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. BM25 (Best Matching 25)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bm25-formula" class="md-nav__link">
    <span class="md-ellipsis">
      
        BM25 Formula
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-improvements-over-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Improvements Over TF-IDF
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bm25-vs-tf-idf" class="md-nav__link">
    <span class="md-ellipsis">
      
        BM25 vs. TF-IDF
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-why-bm25-ranks-better" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example: Why BM25 Ranks Better
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-bm25" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use BM25
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-splade" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. SPLADE
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. SPLADE">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-splade-works-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        How SPLADE Works (Step by Step)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splade-scoring-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        SPLADE Scoring Function
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#splade-vs-bm25" class="md-nav__link">
    <span class="md-ellipsis">
      
        SPLADE vs. BM25
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-splade" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use SPLADE
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-sentence-transformers-dense-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Sentence Transformers (Dense Retrieval)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Sentence Transformers (Dense Retrieval)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-they-work-step-by-step" class="md-nav__link">
    <span class="md-ellipsis">
      
        How They Work (Step by Step)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-mean-pooling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Mean Pooling?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    <span class="md-ellipsis">
      
        Training
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sentence-transformers-vs-sparse-retrieval" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sentence Transformers vs. Sparse Retrieval
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-retrieval-method-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Retrieval Method Comparison
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-interview-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Interview Questions
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Retrieval Methods</h1>

<h2 id="1-overview">1. Overview<a class="headerlink" href="#1-overview" title="Permanent link">&para;</a></h2>
<p>Retrieval is the single most important factor in RAG quality. If the right document is not retrieved, the LLM cannot recover. This section covers the main retrieval algorithms from classical to neural, and how they compare.</p>
<hr />
<hr />
<h2 id="2-tf-idf">2. TF-IDF<a class="headerlink" href="#2-tf-idf" title="Permanent link">&para;</a></h2>
<p>TF-IDF (Term Frequency–Inverse Document Frequency) is the foundational lexical retrieval method. It scores documents by combining two signals.</p>
<h3 id="term-frequency-tf">Term Frequency (TF)<a class="headerlink" href="#term-frequency-tf" title="Permanent link">&para;</a></h3>
<p>How often a term appears in the document. Higher frequency → higher score.</p>
<div class="highlight"><pre><span></span><code>TF(t, d) = count(t in d) / total terms in d
</code></pre></div>
<p>Variants like logarithmic TF reduce the impact of very frequent terms.</p>
<hr />
<h3 id="inverse-document-frequency-idf">Inverse Document Frequency (IDF)<a class="headerlink" href="#inverse-document-frequency-idf" title="Permanent link">&para;</a></h3>
<p>How rare a term is across the corpus. Rare terms score higher; common words ("the", "is") score near zero.</p>
<div class="highlight"><pre><span></span><code>IDF(t) = log(N / (1 + df(t)))
</code></pre></div>
<p>Where N is the total number of documents and df(t) is the number containing term t.</p>
<hr />
<h3 id="tf-idf-score">TF-IDF Score<a class="headerlink" href="#tf-idf-score" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>TF-IDF(t, d) = TF(t, d) × IDF(t)
</code></pre></div>
<p>A high score indicates a term that is both locally frequent and globally distinctive.</p>
<hr />
<p><strong>Strengths</strong></p>
<ul>
<li>Simple, no training required, interpretable, fast.</li>
<li>Works well for exact and partial lexical matches.</li>
</ul>
<hr />
<p><strong>Weaknesses</strong></p>
<ul>
<li>No semantic understanding — requires exact word overlap.</li>
<li>Assumes term independence (bag-of-words).</li>
<li>Linear TF with no saturation — keyword stuffing inflates scores.</li>
<li>Ignores word order and syntax.</li>
</ul>
<hr />
<hr />
<h2 id="3-bm25-best-matching-25">3. BM25 (Best Matching 25)<a class="headerlink" href="#3-bm25-best-matching-25" title="Permanent link">&para;</a></h2>
<p>BM25 is the go-to lexical retrieval baseline and a direct improvement over TF-IDF. It is probabilistically motivated and addresses TF-IDF's two main weaknesses: <strong>term frequency saturation</strong> and <strong>document length normalisation</strong>.</p>
<h3 id="bm25-formula">BM25 Formula<a class="headerlink" href="#bm25-formula" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>BM25(d, q) = Σ IDF(t) × [tf(t,d) × (k₁ + 1)] / [tf(t,d) + k₁ × (1 - b + b × |d|/avgdl)]
</code></pre></div>
<p>Where:</p>
<ul>
<li><code>tf(t, d)</code> — term frequency of t in document d</li>
<li><code>|d|</code> — length of document d</li>
<li><code>avgdl</code> — average document length in the corpus</li>
<li><code>k₁</code> — controls term frequency saturation (typically 1.2–2.0)</li>
<li><code>b</code> — controls length normalisation strength (typically 0.75)</li>
</ul>
<hr />
<h3 id="key-improvements-over-tf-idf">Key Improvements Over TF-IDF<a class="headerlink" href="#key-improvements-over-tf-idf" title="Permanent link">&para;</a></h3>
<p><strong>Term Frequency Saturation:</strong> BM25 assumes diminishing returns for repeated terms. The first few occurrences matter most; additional repetitions contribute progressively less. This prevents keyword stuffing from dominating rankings.</p>
<p><strong>Document Length Normalisation:</strong> Longer documents are explicitly penalised via the <code>b</code> parameter. Setting b=0 disables normalisation; b=1 applies full normalisation. TF-IDF only applies weak or implicit normalisation.</p>
<p><strong>Modified IDF:</strong></p>
<p><div class="highlight"><pre><span></span><code>IDF(t) = log((N - df(t) + 0.5) / (df(t) + 0.5))
</code></pre></div>
More robust for rare and common terms than the basic IDF formula.</p>
<hr />
<h3 id="bm25-vs-tf-idf">BM25 vs. TF-IDF<a class="headerlink" href="#bm25-vs-tf-idf" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>TF-IDF</th>
<th>BM25</th>
</tr>
</thead>
<tbody>
<tr>
<td>Term frequency</td>
<td>Linear — repeats always increase score</td>
<td>Saturated — diminishing returns past threshold</td>
</tr>
<tr>
<td>Length normalisation</td>
<td>Weak or implicit</td>
<td>Explicit, tunable via b</td>
</tr>
<tr>
<td>Tuning parameters</td>
<td>None</td>
<td>k₁ (saturation) and b (length norm)</td>
</tr>
<tr>
<td>Ranking quality</td>
<td>Good baseline</td>
<td>Better; closer to human judgment</td>
</tr>
<tr>
<td>Requires training</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="example-why-bm25-ranks-better">Example: Why BM25 Ranks Better<a class="headerlink" href="#example-why-bm25-ranks-better" title="Permanent link">&para;</a></h3>
<p><strong>Corpus:</strong></p>
<ul>
<li>D1: "deep learning deep learning deep learning tutorial"</li>
<li>D2: "deep learning tutorial"</li>
<li>D3: "deep learning introduction overview"</li>
</ul>
<p><strong>Query:</strong> "deep learning tutorial"</p>
<ul>
<li>TF-IDF ranks: D1 &gt; D2 &gt; D3 — D1 wins purely due to repetition of "deep learning".</li>
<li>BM25 ranks: D2 &gt; D1 &gt; D3 — D1's score saturates; D2's shorter length gives it a boost. D2 is more concise and directly on-topic.</li>
</ul>
<p>BM25 aligns with human intuition: repeating the same phrase doesn't make a document more relevant.</p>
<h3 id="when-to-use-bm25">When to Use BM25<a class="headerlink" href="#when-to-use-bm25" title="Permanent link">&para;</a></h3>
<ul>
<li>Exact keyword matches matter (names, IDs, error codes, product codes).</li>
<li>No training budget or labelled data.</li>
<li>Fast, no-GPU, interpretable baseline.</li>
<li>As the sparse component of a hybrid retrieval system.</li>
</ul>
<hr />
<hr />
<h2 id="4-splade">4. SPLADE<a class="headerlink" href="#4-splade" title="Permanent link">&para;</a></h2>
<p>SPLADE (Sparse Lexical and Expansion Model) is a neural sparse retrieval model that bridges classical lexical retrieval (BM25) and dense semantic retrieval. It uses a pretrained transformer to produce sparse vector representations, and critically, it performs <strong>learned term expansion</strong>.</p>
<h3 id="core-idea">Core Idea<a class="headerlink" href="#core-idea" title="Permanent link">&para;</a></h3>
<p>BM25 relies on exact term overlap. SPLADE trains a transformer to assign weights to vocabulary terms — including terms <strong>not present</strong> in the input — based on semantic relevance. Despite using a neural model, the output is a sparse vector compatible with standard inverted-index infrastructure.</p>
<hr />
<h3 id="how-splade-works-step-by-step">How SPLADE Works (Step by Step)<a class="headerlink" href="#how-splade-works-step-by-step" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Input text</strong> is passed through a masked language model (e.g., BERT).</li>
<li><strong>Vocabulary scoring:</strong> For each token position, the model produces a score for every term in the vocabulary. The model answers: "Which vocabulary terms are relevant to this text, even if not explicitly present?"</li>
<li><strong>Non-linearity and sparsification:</strong> Raw scores are transformed using ReLU (removes negatives) + log scaling (controls large activations). Max pooling across token positions produces a single sparse vector.</li>
<li><strong>Result:</strong> One score per vocabulary term; most are zero. Only the most relevant terms remain active.</li>
<li><strong>Inverted index:</strong> Non-zero terms are stored in a standard inverted index — identical infrastructure to BM25.</li>
</ol>
<p><strong>Example expansion:</strong>
- Input: "car repair"
- Expanded active terms: <code>{car: 2.1, repair: 1.9, automobile: 1.4, mechanic: 1.1, engine: 0.8}</code></p>
<p>This allows matching a document about "automobile maintenance" even though neither query word appears in it.</p>
<hr />
<h3 id="splade-scoring-function">SPLADE Scoring Function<a class="headerlink" href="#splade-scoring-function" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>Score(t) = max over positions of log(1 + ReLU(logit_t))
</code></pre></div>
<ul>
<li>ReLU enforces non-negativity</li>
<li>Log scaling controls large activations</li>
<li>Max pooling encourages sparse activation</li>
</ul>
<hr />
<h3 id="splade-vs-bm25">SPLADE vs. BM25<a class="headerlink" href="#splade-vs-bm25" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>BM25</th>
<th>SPLADE</th>
</tr>
</thead>
<tbody>
<tr>
<td>Term weighting</td>
<td>Hand-crafted formula (TF × IDF)</td>
<td>Learned by transformer</td>
</tr>
<tr>
<td>Semantic expansion</td>
<td>None — exact words only</td>
<td>Yes — expands to related terms</td>
</tr>
<tr>
<td>Index compatibility</td>
<td>Inverted index</td>
<td>Inverted index (same infrastructure)</td>
</tr>
<tr>
<td>Interpretability</td>
<td>High</td>
<td>Moderate</td>
</tr>
<tr>
<td>Requires training</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Retrieval quality</td>
<td>Strong baseline</td>
<td>Stronger; approaches dense retrieval</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Think of SPLADE as "BM25 where the term weights and expansions are learned by a language model rather than hand-crafted."</p>
</blockquote>
<hr />
<h3 id="when-to-use-splade">When to Use SPLADE<a class="headerlink" href="#when-to-use-splade" title="Permanent link">&para;</a></h3>
<ul>
<li>Want BM25 efficiency with semantic expansion.</li>
<li>Existing inverted-index infrastructure that cannot be replaced.</li>
<li>Queries use different vocabulary than documents.</li>
<li>As the sparse component in hybrid retrieval alongside dense models.</li>
</ul>
<hr />
<hr />
<h2 id="5-sentence-transformers-dense-retrieval">5. Sentence Transformers (Dense Retrieval)<a class="headerlink" href="#5-sentence-transformers-dense-retrieval" title="Permanent link">&para;</a></h2>
<p>Sentence Transformers are neural models that convert text into dense fixed-size vectors encoding semantic meaning. They are the backbone of dense retrieval in most production RAG systems.</p>
<h3 id="how-they-work-step-by-step">How They Work (Step by Step)<a class="headerlink" href="#how-they-work-step-by-step" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Input text</strong> is passed through a transformer encoder (BERT, RoBERTa, MiniLM, etc.).</li>
<li><strong>Transformer encoding</strong> produces one contextualised embedding per token.</li>
<li><strong>Pooling:</strong> Token embeddings are aggregated into a single fixed-size vector. Mean pooling is most common — it is stable and empirically strong.</li>
<li><strong>L2 normalisation:</strong> The vector is normalised so cosine similarity equals dot product.</li>
<li><strong>Indexing:</strong> Vectors are stored in a vector database for ANN search.</li>
</ol>
<hr />
<h3 id="why-mean-pooling">Why Mean Pooling?<a class="headerlink" href="#why-mean-pooling" title="Permanent link">&para;</a></h3>
<p>Mean pooling averages all token embeddings, including padding tokens (which are typically masked). It is simple, stable, and performs better than CLS-token pooling in most retrieval benchmarks.</p>
<hr />
<h3 id="training">Training<a class="headerlink" href="#training" title="Permanent link">&para;</a></h3>
<p>Sentence Transformers are trained with contrastive objectives:</p>
<ul>
<li>
<p><strong>Multiple Negatives Ranking (MNR) Loss:</strong> In a batch of K query-document pairs, each document serves as a negative for all other queries in the batch. This provides K–1 negatives per query for free — no manual negative labelling needed. This is the standard training approach for models like BGE, E5, and GTE.</p>
</li>
<li>
<p><strong>Triplet Loss:</strong> (anchor, positive, negative) — the model is penalised when the negative is closer to the anchor than the positive.</p>
</li>
</ul>
<hr />
<h3 id="sentence-transformers-vs-sparse-retrieval">Sentence Transformers vs. Sparse Retrieval<a class="headerlink" href="#sentence-transformers-vs-sparse-retrieval" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Sparse (BM25 / SPLADE)</th>
<th>Dense (Sentence Transformers)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Semantic matching</td>
<td>Limited / partial</td>
<td>Strong — handles paraphrases natively</td>
</tr>
<tr>
<td>Exact match</td>
<td>Strong</td>
<td>Weak — misses rare keywords and IDs</td>
</tr>
<tr>
<td>Interpretability</td>
<td>High</td>
<td>Low — black box</td>
</tr>
<tr>
<td>Infrastructure</td>
<td>Inverted index</td>
<td>Vector database with ANN index</td>
</tr>
<tr>
<td>Training required</td>
<td>No (BM25) / Yes (SPLADE)</td>
<td>Yes</td>
</tr>
<tr>
<td>Domain adaptation</td>
<td>Not needed (BM25)</td>
<td>May require fine-tuning</td>
</tr>
</tbody>
</table>
<hr />
<h3 id="when-to-use">When to Use<a class="headerlink" href="#when-to-use" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Dense retrieval:</strong> Natural language queries; paraphrase matching; fine-grained semantic similarity matters.</li>
<li><strong>Sparse retrieval:</strong> Queries with specific identifiers; corpus has precise technical terminology.</li>
<li><strong>Hybrid (recommended for production):</strong> Most systems combine both to cover complementary failure modes.</li>
</ul>
<hr />
<hr />
<h2 id="6-retrieval-method-comparison">6. Retrieval Method Comparison<a class="headerlink" href="#6-retrieval-method-comparison" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Method</th>
<th>Semantic Matching</th>
<th>Exact Match</th>
<th>Training Needed</th>
<th>Infrastructure</th>
<th>Best Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>TF-IDF</td>
<td>None</td>
<td>Good</td>
<td>No</td>
<td>Inverted index</td>
<td>Simple baseline</td>
</tr>
<tr>
<td>BM25</td>
<td>None</td>
<td>Strong</td>
<td>No</td>
<td>Inverted index</td>
<td>Keyword-heavy queries; default lexical baseline</td>
</tr>
<tr>
<td>SPLADE</td>
<td>Via expansion</td>
<td>Strong</td>
<td>Yes</td>
<td>Inverted index</td>
<td>Neural sparse; efficient + semantic</td>
</tr>
<tr>
<td>Dense bi-encoder</td>
<td>Strong</td>
<td>Weak</td>
<td>Yes</td>
<td>Vector DB + ANN</td>
<td>Natural language queries; semantic similarity</td>
</tr>
<tr>
<td>Hybrid (dense + sparse)</td>
<td>Strong</td>
<td>Strong</td>
<td>Yes (dense part)</td>
<td>Both</td>
<td>Production RAG; best overall quality</td>
</tr>
</tbody>
</table>
<hr />
<hr />
<h2 id="7-interview-questions">7. Interview Questions<a class="headerlink" href="#7-interview-questions" title="Permanent link">&para;</a></h2>
<p><strong>Q: Why is BM25 still widely used despite neural models being more powerful?</strong></p>
<p>A: BM25 requires no training, has no GPU inference cost, is fully interpretable, and handles exact keyword matching better than dense models. It's also very fast on inverted indexes. In hybrid systems, BM25 and dense retrieval complement each other — BM25 catches cases the dense model misses (exact terms, IDs) and dense models catch paraphrases BM25 misses.</p>
<hr />
<p><strong>Q: What is the difference between SPLADE and a dense bi-encoder?</strong></p>
<p>A: SPLADE produces a sparse vector over the vocabulary and is indexed in an inverted index — fast, memory-efficient, and interpretable. A dense bi-encoder produces a continuous low-dimensional vector indexed in a vector DB with ANN search. SPLADE uses a neural model for semantic expansion but retains sparse representation. In practice SPLADE often outperforms BM25 and approaches dense retrieval quality, while remaining compatible with existing inverted-index infrastructure.</p>
<hr />
<p><strong>Q: What is Reciprocal Rank Fusion (RRF) and why is it preferred over score interpolation?</strong></p>
<p>A: RRF combines ranked lists from multiple retrievers by summing 1/(k + rank) for each document across all retrievers (k is typically 60). It is preferred over linear score interpolation because it is robust to score scale differences between retrievers — BM25 scores and cosine similarities live on completely different scales. RRF requires no weight tuning and typically matches or outperforms tuned linear combinations.</p>
<hr />
<p><strong>Q: Why might a dense retriever miss a relevant document that BM25 finds?</strong></p>
<p>A: Dense retrievers encode the entire meaning of text into a single vector — rare or highly specific terms may get diluted in the embedding. If a document is only relevant because it contains a specific product ID, error code, or proper noun, a dense embedding may not preserve that specificity. BM25's exact-match scoring handles these cases naturally. This is why hybrid retrieval consistently outperforms either method alone.</p>
<hr />
<p><strong>Q: What preprocessing decisions most affect BM25 performance?</strong></p>
<p>A: Stopword removal, stemming/lemmatisation, and tokenisation. Removing stopwords (words like "the", "is") reduces noise. Stemming conflates "running" and "run", improving recall but potentially harming precision. BM25's k₁ and b parameters also have a significant effect and should be tuned on held-out validation data rather than left at defaults.</p>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.expand", "navigation.top", "search.highlight", "search.share", "content.code.copy", "mathjax"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>